{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Story generator",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NreMuR_wUa3"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils \n",
        "import tensorflow as tf\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import warnings\n",
        "from nltk.corpus import stopwords\n",
        "# from langdetect import detect\n",
        "import nltk\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "uTrDCP0Dwql7",
        "outputId": "92982091-12f0-4506-e9ad-bcd7f3c5fda3"
      },
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/jessiececilya/Projects/main/hippoCorpusV2.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AssignmentId</th>\n",
              "      <th>WorkTimeInSeconds</th>\n",
              "      <th>WorkerId</th>\n",
              "      <th>annotatorAge</th>\n",
              "      <th>annotatorGender</th>\n",
              "      <th>annotatorRace</th>\n",
              "      <th>distracted</th>\n",
              "      <th>draining</th>\n",
              "      <th>frequency</th>\n",
              "      <th>importance</th>\n",
              "      <th>logTimeSinceEvent</th>\n",
              "      <th>mainEvent</th>\n",
              "      <th>memType</th>\n",
              "      <th>mostSurprising</th>\n",
              "      <th>openness</th>\n",
              "      <th>recAgnPairId</th>\n",
              "      <th>recImgPairId</th>\n",
              "      <th>similarity</th>\n",
              "      <th>similarityReason</th>\n",
              "      <th>story</th>\n",
              "      <th>stressful</th>\n",
              "      <th>summary</th>\n",
              "      <th>timeSinceEvent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32RIADZISTQWI5XIVG5BN0VMYFRS4U</td>\n",
              "      <td>1641</td>\n",
              "      <td>XI8VK89S</td>\n",
              "      <td>25.0</td>\n",
              "      <td>man</td>\n",
              "      <td>white</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.499810</td>\n",
              "      <td>attending a show</td>\n",
              "      <td>imagined</td>\n",
              "      <td>when I got concert tickets</td>\n",
              "      <td>0.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3018Q3ZVOJCZJFDMPSFXATCQ4DARA2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>I've been to a couple concerts, but not many.</td>\n",
              "      <td>Concerts are my most favorite thing, and my bo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>My boyfriend and I went to a concert together ...</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3018Q3ZVOJCZJFDMPSFXATCQ4DARA2</td>\n",
              "      <td>1245</td>\n",
              "      <td>1HN5ZZ1D</td>\n",
              "      <td>25.0</td>\n",
              "      <td>woman</td>\n",
              "      <td>white</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.499810</td>\n",
              "      <td>a concert.</td>\n",
              "      <td>recalled</td>\n",
              "      <td>we saw the beautiful sky.</td>\n",
              "      <td>1.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3018Q3ZVOJCZJFDMPSFXATCQ4DARA2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The day started perfectly, with a great drive ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>My boyfriend and I went to a concert together ...</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3IRIK4HM3B6UQBC0HI8Q5TBJZLEC61</td>\n",
              "      <td>1159</td>\n",
              "      <td>8SBPL7EI</td>\n",
              "      <td>35.0</td>\n",
              "      <td>woman</td>\n",
              "      <td>black</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.010635</td>\n",
              "      <td>my sister having her twins a little early</td>\n",
              "      <td>imagined</td>\n",
              "      <td>she went into labor early</td>\n",
              "      <td>0.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3018Q3ZVOJCZJFDMPSFXATCQG04RAI</td>\n",
              "      <td>3.0</td>\n",
              "      <td>I am a mother myself</td>\n",
              "      <td>It seems just like yesterday but today makes f...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>My sister gave birth to my twin niece and neph...</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3018Q3ZVOJCZJFDMPSFXATCQG04RAI</td>\n",
              "      <td>500</td>\n",
              "      <td>M1QQED2V</td>\n",
              "      <td>30.0</td>\n",
              "      <td>woman</td>\n",
              "      <td>white</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.010635</td>\n",
              "      <td>meeting my twin niece and nephew.</td>\n",
              "      <td>recalled</td>\n",
              "      <td>finding out they were healthy.</td>\n",
              "      <td>1.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3018Q3ZVOJCZJFDMPSFXATCQG04RAI</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Five months ago, my niece and nephew were born...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>My sister gave birth to my twin niece and neph...</td>\n",
              "      <td>150.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3MTMREQS4W44RBU8OMP3XSK8NMJAWZ</td>\n",
              "      <td>1074</td>\n",
              "      <td>DU3RPZDB</td>\n",
              "      <td>25.0</td>\n",
              "      <td>man</td>\n",
              "      <td>white</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.401197</td>\n",
              "      <td>the consequences of going to burning man</td>\n",
              "      <td>imagined</td>\n",
              "      <td>When I don't answer the phone in case I owe th...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3018Q3ZVOJCZJFDMPSFXATCQG06AR3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Because I also have money problems</td>\n",
              "      <td>About a month ago I went to burning man. I was...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>It is always a journey for me to go to burning...</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     AssignmentId  ...  timeSinceEvent\n",
              "0  32RIADZISTQWI5XIVG5BN0VMYFRS4U  ...            90.0\n",
              "1  3018Q3ZVOJCZJFDMPSFXATCQ4DARA2  ...            90.0\n",
              "2  3IRIK4HM3B6UQBC0HI8Q5TBJZLEC61  ...           150.0\n",
              "3  3018Q3ZVOJCZJFDMPSFXATCQG04RAI  ...           150.0\n",
              "4  3MTMREQS4W44RBU8OMP3XSK8NMJAWZ  ...            30.0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhg2wmkJx_9p",
        "outputId": "a77b5f1c-6b53-413d-b1ab-3967ae78b568"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKDE181n0FiT"
      },
      "source": [
        "corpus=df['summary'].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EStHRSLN0hn5"
      },
      "source": [
        "\n",
        "def text_cleaner(text):\n",
        "    text = \"\".join(car for car in text if car not in string.punctuation).lower()\n",
        "    text = text.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
        "    return text\n",
        "\n",
        "corpus = [text_cleaner(line) for line in corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3GKMu9k0lW3",
        "outputId": "bf1a8b00-fc7f-4f64-9baa-74ede277b71a"
      },
      "source": [
        "corpus = corpus[:5000]\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index) + 1\n",
        "total_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTDvdxx_0qEr"
      },
      "source": [
        "input_sequences =[]\n",
        "\n",
        "for sentence in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxfNi9pns8w6"
      },
      "source": [
        "input_sequences=input_sequences[:30000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJJ46WVZ0sv7"
      },
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, \n",
        "                                         maxlen=max_sequence_len, \n",
        "                                         padding='pre'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfa41PZ60vaG"
      },
      "source": [
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "# create one-hot encoding of the labels\n",
        "label = tensorflow.keras.utils.to_categorical(label, num_classes=total_words)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b7KIZNaxrWr",
        "outputId": "7a132874-5a76-4d6f-c38d-d8e50255e476"
      },
      "source": [
        "input_sequences.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0rs2Jx6xu07",
        "outputId": "eeb47756-f275-40c5-e3f9-26ce720b6a8e"
      },
      "source": [
        "print(label[0])\n",
        "print(label[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. ... 0. 0. 0.]\n",
            "(5846,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-rBtnw31Lss",
        "outputId": "88428ac2-4c07-4302-f5a2-b3491796bff3"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(200))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 62, 10)            58460     \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 200)               168800    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5846)              1175046   \n",
            "=================================================================\n",
            "Total params: 1,402,306\n",
            "Trainable params: 1,402,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sab2l66YsrxP",
        "outputId": "4607d3f1-d065-428b-a80b-74a9b741aa09"
      },
      "source": [
        "history = model.fit(predictors, label, epochs=100,  verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "938/938 [==============================] - 127s 133ms/step - loss: 6.6436 - accuracy: 0.0378\n",
            "Epoch 2/100\n",
            "938/938 [==============================] - 125s 133ms/step - loss: 5.9078 - accuracy: 0.0526\n",
            "Epoch 3/100\n",
            "938/938 [==============================] - 126s 134ms/step - loss: 5.5372 - accuracy: 0.0753\n",
            "Epoch 4/100\n",
            "938/938 [==============================] - 125s 134ms/step - loss: 5.1431 - accuracy: 0.0946\n",
            "Epoch 5/100\n",
            "938/938 [==============================] - 126s 134ms/step - loss: 4.7278 - accuracy: 0.1223\n",
            "Epoch 6/100\n",
            "938/938 [==============================] - 125s 134ms/step - loss: 4.2666 - accuracy: 0.1503\n",
            "Epoch 7/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 3.8213 - accuracy: 0.1969\n",
            "Epoch 8/100\n",
            "938/938 [==============================] - 126s 134ms/step - loss: 3.4020 - accuracy: 0.2591\n",
            "Epoch 9/100\n",
            "938/938 [==============================] - 125s 134ms/step - loss: 3.0291 - accuracy: 0.3236\n",
            "Epoch 10/100\n",
            "938/938 [==============================] - 126s 134ms/step - loss: 2.6835 - accuracy: 0.3876\n",
            "Epoch 11/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 2.4299 - accuracy: 0.4380\n",
            "Epoch 12/100\n",
            "938/938 [==============================] - 126s 134ms/step - loss: 2.1770 - accuracy: 0.4892\n",
            "Epoch 13/100\n",
            "938/938 [==============================] - 126s 135ms/step - loss: 1.9791 - accuracy: 0.5307\n",
            "Epoch 14/100\n",
            "938/938 [==============================] - 126s 135ms/step - loss: 1.8036 - accuracy: 0.5690\n",
            "Epoch 15/100\n",
            "938/938 [==============================] - 126s 134ms/step - loss: 1.6474 - accuracy: 0.6053\n",
            "Epoch 16/100\n",
            "938/938 [==============================] - 125s 134ms/step - loss: 1.4982 - accuracy: 0.6362\n",
            "Epoch 17/100\n",
            "938/938 [==============================] - 125s 134ms/step - loss: 1.3862 - accuracy: 0.6597\n",
            "Epoch 18/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 1.2763 - accuracy: 0.6826\n",
            "Epoch 19/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 1.1981 - accuracy: 0.7033\n",
            "Epoch 20/100\n",
            "938/938 [==============================] - 127s 136ms/step - loss: 1.1121 - accuracy: 0.7218\n",
            "Epoch 21/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 1.0301 - accuracy: 0.7399\n",
            "Epoch 22/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.9774 - accuracy: 0.7559\n",
            "Epoch 23/100\n",
            "938/938 [==============================] - 128s 136ms/step - loss: 0.9188 - accuracy: 0.7696\n",
            "Epoch 24/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.8570 - accuracy: 0.7799\n",
            "Epoch 25/100\n",
            "938/938 [==============================] - 127s 136ms/step - loss: 0.8237 - accuracy: 0.7872\n",
            "Epoch 26/100\n",
            "938/938 [==============================] - 128s 136ms/step - loss: 0.7825 - accuracy: 0.7952\n",
            "Epoch 27/100\n",
            "938/938 [==============================] - 128s 136ms/step - loss: 0.7345 - accuracy: 0.8097\n",
            "Epoch 28/100\n",
            "938/938 [==============================] - 127s 136ms/step - loss: 0.7008 - accuracy: 0.8166\n",
            "Epoch 29/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.7007 - accuracy: 0.8145\n",
            "Epoch 30/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.6597 - accuracy: 0.8268\n",
            "Epoch 31/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.6409 - accuracy: 0.8323\n",
            "Epoch 32/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.6074 - accuracy: 0.8411\n",
            "Epoch 33/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.5989 - accuracy: 0.8405\n",
            "Epoch 34/100\n",
            "938/938 [==============================] - 126s 135ms/step - loss: 0.5672 - accuracy: 0.8468\n",
            "Epoch 35/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.5559 - accuracy: 0.8533\n",
            "Epoch 36/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.5353 - accuracy: 0.8591\n",
            "Epoch 37/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.5384 - accuracy: 0.8536\n",
            "Epoch 38/100\n",
            "938/938 [==============================] - 126s 135ms/step - loss: 0.5298 - accuracy: 0.8559\n",
            "Epoch 39/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.4938 - accuracy: 0.8659\n",
            "Epoch 40/100\n",
            "938/938 [==============================] - 127s 136ms/step - loss: 0.4923 - accuracy: 0.8643\n",
            "Epoch 41/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.4798 - accuracy: 0.8688\n",
            "Epoch 42/100\n",
            "938/938 [==============================] - 127s 136ms/step - loss: 0.4727 - accuracy: 0.8706\n",
            "Epoch 43/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.4521 - accuracy: 0.8755\n",
            "Epoch 44/100\n",
            "938/938 [==============================] - 127s 135ms/step - loss: 0.4670 - accuracy: 0.8731\n",
            "Epoch 45/100\n",
            "938/938 [==============================] - 128s 137ms/step - loss: 0.4590 - accuracy: 0.8735\n",
            "Epoch 46/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.4458 - accuracy: 0.8744\n",
            "Epoch 47/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.4330 - accuracy: 0.8828\n",
            "Epoch 48/100\n",
            "938/938 [==============================] - 128s 136ms/step - loss: 0.4276 - accuracy: 0.8821\n",
            "Epoch 49/100\n",
            "938/938 [==============================] - 128s 136ms/step - loss: 0.4219 - accuracy: 0.8842\n",
            "Epoch 50/100\n",
            "938/938 [==============================] - 128s 137ms/step - loss: 0.5144 - accuracy: 0.8526\n",
            "Epoch 51/100\n",
            "938/938 [==============================] - 128s 136ms/step - loss: 0.4113 - accuracy: 0.8870\n",
            "Epoch 52/100\n",
            "938/938 [==============================] - 128s 137ms/step - loss: 0.3793 - accuracy: 0.8960\n",
            "Epoch 53/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.3765 - accuracy: 0.8956\n",
            "Epoch 54/100\n",
            "938/938 [==============================] - 128s 137ms/step - loss: 0.4210 - accuracy: 0.8833\n",
            "Epoch 55/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.4013 - accuracy: 0.8889\n",
            "Epoch 56/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.3749 - accuracy: 0.8961\n",
            "Epoch 57/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.4012 - accuracy: 0.8859\n",
            "Epoch 58/100\n",
            "938/938 [==============================] - 128s 137ms/step - loss: 0.3946 - accuracy: 0.8901\n",
            "Epoch 59/100\n",
            "938/938 [==============================] - 128s 137ms/step - loss: 0.3851 - accuracy: 0.8909\n",
            "Epoch 60/100\n",
            "938/938 [==============================] - 128s 137ms/step - loss: 0.3771 - accuracy: 0.8943\n",
            "Epoch 61/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3999 - accuracy: 0.8865\n",
            "Epoch 62/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3741 - accuracy: 0.8940\n",
            "Epoch 63/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3622 - accuracy: 0.8992\n",
            "Epoch 64/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3942 - accuracy: 0.8876\n",
            "Epoch 65/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3687 - accuracy: 0.8961\n",
            "Epoch 66/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3709 - accuracy: 0.8978\n",
            "Epoch 67/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3717 - accuracy: 0.8947\n",
            "Epoch 68/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3616 - accuracy: 0.8976\n",
            "Epoch 69/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.3831 - accuracy: 0.8893\n",
            "Epoch 70/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3514 - accuracy: 0.9024\n",
            "Epoch 71/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3635 - accuracy: 0.8986\n",
            "Epoch 72/100\n",
            "938/938 [==============================] - 129s 137ms/step - loss: 0.3840 - accuracy: 0.8912\n",
            "Epoch 73/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3715 - accuracy: 0.8953\n",
            "Epoch 74/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.3695 - accuracy: 0.8959\n",
            "Epoch 75/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3419 - accuracy: 0.9055\n",
            "Epoch 76/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3912 - accuracy: 0.8877\n",
            "Epoch 77/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3635 - accuracy: 0.8937\n",
            "Epoch 78/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3368 - accuracy: 0.9037\n",
            "Epoch 79/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.4199 - accuracy: 0.8805\n",
            "Epoch 80/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.3495 - accuracy: 0.8995\n",
            "Epoch 81/100\n",
            "938/938 [==============================] - 131s 139ms/step - loss: 0.3508 - accuracy: 0.9004\n",
            "Epoch 82/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.3551 - accuracy: 0.8988\n",
            "Epoch 83/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.3537 - accuracy: 0.8984\n",
            "Epoch 84/100\n",
            "938/938 [==============================] - 131s 139ms/step - loss: 0.3237 - accuracy: 0.9082\n",
            "Epoch 85/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3453 - accuracy: 0.9006\n",
            "Epoch 86/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3634 - accuracy: 0.8963\n",
            "Epoch 87/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.3540 - accuracy: 0.8982\n",
            "Epoch 88/100\n",
            "938/938 [==============================] - 131s 139ms/step - loss: 0.3431 - accuracy: 0.9033\n",
            "Epoch 89/100\n",
            "938/938 [==============================] - 131s 139ms/step - loss: 0.3415 - accuracy: 0.9035\n",
            "Epoch 90/100\n",
            "938/938 [==============================] - 131s 139ms/step - loss: 0.3422 - accuracy: 0.9011\n",
            "Epoch 91/100\n",
            "938/938 [==============================] - 132s 141ms/step - loss: 0.3212 - accuracy: 0.9067\n",
            "Epoch 92/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.3299 - accuracy: 0.9061\n",
            "Epoch 93/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.3613 - accuracy: 0.8955\n",
            "Epoch 94/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3323 - accuracy: 0.9024\n",
            "Epoch 95/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3240 - accuracy: 0.9084\n",
            "Epoch 96/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3349 - accuracy: 0.9029\n",
            "Epoch 97/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3545 - accuracy: 0.8983\n",
            "Epoch 98/100\n",
            "938/938 [==============================] - 130s 139ms/step - loss: 0.5665 - accuracy: 0.8364\n",
            "Epoch 99/100\n",
            "938/938 [==============================] - 130s 138ms/step - loss: 0.3581 - accuracy: 0.8984\n",
            "Epoch 100/100\n",
            "938/938 [==============================] - 129s 138ms/step - loss: 0.3107 - accuracy: 0.9110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd1jf3ad2El4"
      },
      "source": [
        "seed_text = \"It is a beautiful morning\"\n",
        "next_words = 6\n",
        "  \n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.predict_classes(token_list, verbose=0)\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "    # if len(seed_text) % 10 == 0 :\n",
        "    #     seed_text+= '\\n'\n",
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGntEPln2LAy"
      },
      "source": [
        "model.save('withpunct.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU2bbfqhTwDx"
      },
      "source": [
        "model=load_model('withpunct.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0Fk_owHOoP_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}